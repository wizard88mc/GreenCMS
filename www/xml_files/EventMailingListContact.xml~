<?xml version="1.0" encoding="UTF-8"?>
<TableEvents xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="databaseDefinition/EventMailingListContact.xsd">







<Event language="en">
	<ID>6</ID>
	<Title>Batch resolution protocols for wireless and RFID networks </Title>
	<Date>2012-03-30</Date>
	<Time>15:30:00</Time>
	<Place>Aula 1BC50 - Torre di Archimede - Via Trieste 63 </Place>
	<Speaker>Andrea Zanella</Speaker>
	<From>Dip. Ing. dell'Informazione - UNIPD</From>
	<SpeakerCV>Andrea Zanella is Assistant Professor at the Department of Information Engineering (DEI), University of Padova (ITALY). He received the Laurea degree in Computer Engineering in 1998, from the same University, and the PhD degree in Electronic and Telecommunications Engineering, in 2002. Before that, he spent nine months as visiting scholar at the Department of Computer Science of the University of California, Los Angeles (UCLA), where he worked with Prof. Mario Gerla on Wireless Networks and Wireless Access to Internet. </SpeakerCV>
	<Abstract>A batch resolution algorithm (BRA) is a channel access policy used by a group of nodes (the batch) that simultaneously generate a packet for a common receiver. The aim is to minimize the batch resolution interval (BRI), i.e., the time it takes for all nodes in the batch to successfully deliver their packet. Most of existing BRAs require immediate feedback after each packet transmission, and typically assume the feedback time is negligible. This conjecture, however, fails to apply in practical high rate wireless systems, so that the classical performance analysis of BRAs may be overoptimistic.
In this talk we give a quick overview of the classical tree-based BRAs and, then, we present a novel BRA, named Adaptive Batch Resolution Algorithm with Deferred Feedback (ABRADE), which waives the immediate feedback approach in favor of a deferred feedback method, based on a framed ALOHA access scheme. The frame length is optimized by using a dynamic programming technique in order to minimize the BRI, under the assumption that the batch size is known. This assumption is then removed by enhancing ABRADE with a batch size estimate module. The new algorithm, called ABRADE+, is compared against the best performing BRAs based on the immediate feedback paradigm, showing better performance both in case of partial and no prior knowledge of the batch multiplicity.</Abstract>
</Event><Event language="en">
	<ID>5</ID>
	<Title>Efficient Source Authentication Schemes in Wireless Sensor Networks</Title>
	<Date>2012-03-28</Date>
	<Time>11:00:00</Time>
	<Place>aula 2BC30 Torre Archimede</Place>
	<Speaker>Wafa Ben Jaballah</Speaker>
	<From>Unversity of Bordeux</From>
	<SpeakerCV/>
	<Abstract>Wireless sensor networks (WSN) are being widely deployed in military, healthcare and commercial environments. Since sensor networks pose unique challenges, traditional security methods, commonly used in enterprise networks, cannot be directly applied. In particular, broadcast source authentication is a critical security service in wireless sensor networks since it allows senders to broadcast messages to multiple receivers in a secure way. Public-key cryptography based solutions such as Elliptic Curve Cryptography (ECC) and Identity Based Cryptography (IBC) have been proposed but they all suffer from severe energy depletion attacks, resulting from a high computational and communication overheads. We present  novel symmetric-key-based authentication schemes that exhibit low broadcast authentication overhead and thus avoiding the problem flaws inherent to the public key cryptography based schemes. Our schemes are built upon the integration of multi-level μTesla protocol, staggered authentication and the Bloom Filter. 
 Experimental results demonstrate that our authentication schemes are very efficient in terms of  authentication delay, authentication probability, delay of forged packets in the receiver’s buffer, memory, and energy consumption related to both computation and communication.</Abstract>
</Event><Event language="it">
	<ID>4</ID>
	<Title>Toward the creation of a Green Content Management System</Title>
	<Date>2012-02-09</Date>
	<Time>11:30:00</Time>
	<Place>2BC60</Place>
	<Speaker>Matteo Ciman</Speaker>
	<From/>
	<SpeakerCV/>
	<Abstract>Il sito delle lauree in Informatica [link]informatica.math.unipd.it[/link] è stato aggiornato implementando un particolare CMS che minimizza il lavoro del server ed il tempo di risposta per i visitatori. In questo seminario verranno presentate le diverse tecniche e strategie adottate. </Abstract>
</Event><Event language="en">
	<ID>3</ID>
	<Title>CRePE: a System for Enforcing Fine-Grained Context-Related Policies on Android</Title>
	<Date>2012-01-12</Date>
	<Time>15:00:00</Time>
	<Place>1C150</Place>
	<Speaker>Mauro Conti and Earlence Fernandes</Speaker>
	<From>Univ. di Padova and Vrije Universiteit Amsterdam, NL</From>
	<SpeakerCV/>
	<Abstract>Current smartphone systems allow the user to use only marginally contextual information to specify the behaviour of the applications: this hinders the wide adoption of this technology to its full potential. We fill this gap by proposing CRePE, a fine-grained Context-Related Policy Enforcement System for Android. While the concept of context-related access control is not new, this is the first work that brings this concept into the smartphone environment. In particular, in our work a context can be defined by: the status of variables sensed by physical (low level) sensors, like time and location; additional processing on these data via software (high level) sensors; or particular interactions with the users or third parties. CRePE allows context-related policies to be set (even at runtime) by both the user and authorized third parties locally (via an application) or remotely (via SMS, MMS, Bluetooth, and QR-code). A thorough set of experiments shows that our full implementation of CRePE has a negligible overhead in terms of energy consumption, time, and storage, making our system ready for a production environment. In this talk, we will present CRePE, together with a demo session and the discussion of the most interesting insights in the programming of CRePE (which resulted in a modified version of Android). </Abstract>
</Event><Event language="en">
	<ID>2</ID>
	<Title>What can we do in CP but not in SAT or ILP? </Title>
	<Date>2011-12-16</Date>
	<Time>14:00:00</Time>
	<Place>2AB45</Place>
	<Speaker>Prof. Toby Walsh</Speaker>
	<From>NICTA and University of New South Wales</From>
	<SpeakerCV>Prof. Walsh is one of the top scientists in the areas of Artificial Intelligence and Constraint Programming. He has been program chair of IJCAI (the main international conference for Artificial Intelligence) in 2011, and has published more than 300 papers in major international
journals and conferences. </SpeakerCV>
	<Abstract>The talk explores the connections between Integer Linear Programming (ILP), propositional satisfiability (SAT) and Constraint Programming (CP). The focus of the talk is on global constraints like AllDifferent. These are one of the key distinguishing features of constraint programming. I describe recent work on simulating the actions of global
constraints with simple decompositions that can be implemented using SAT clauses or ILP models. Based on powerful lower bounds from circuit complexity, I argue that there are, however, some things that cannot be effectively simulated in ILP or SAT. The conclusion is that not everything can be done in SAT or ILP and we do in fact need some of the powerful algorithmic techniques provided by CP. </Abstract>
</Event><Event language="en">
	<ID>1</ID>
	<Title>Machine Intelligence, Generalized Rough Sets and Granular Mining: Concepts, Features and Applications</Title>
	<Date>2011-11-25</Date>
	<Time>15:00:00</Time>
	<Place>Aula 1AD100, Torre Archimede</Place>
	<Speaker>Prof. Sankar K. Pal</Speaker>
	<From>Indian Statistical Institute, India</From>
	<SpeakerCV>Sankar K. Pal  (www.isical.ac.in/~sankar) is a Distinguished Scientist of the Indian Statistical Institute  and a former Director. He is also a  J.C. Bose  Fellow of  the Govt.  of India.  He founded  the Machine Intelligence  Unit  and the  Center  for  Soft  Computing Research:  A
National Facility in the Institute in Calcutta. He received a Ph.D. in Radio Physics and Electronics from the University of Calcutta in 1979, and  another  Ph.D. in  Electrical  Engineering  along  with DIC  from Imperial  College, University  of London  in  1982. He  worked at  the
University  of California,  Berkeley and  the University  of Maryland, College Park in 1986-87; the NASA Johnson Space Center, Houston, Texas in 1990-92 &amp; 1994; and  in US Naval Research Laboratory, Washington DC in 2004.
Prof. Pal  is a Fellow of the  IEEE, USA, the Academy  of Sciences for the  Developing  World (TWAS),  Italy,  International Association  for Pattern recognition, USA,  International Association of Fuzzy Systems, USA, and  all the four  National Academies for  Science/Engineering in
India.</SpeakerCV>
	<Abstract>Different  components of  machine  intelligence and  their
characteristics are explained.  The  role of rough sets in uncertainty handling and granular computing  is described. The significance of its integration  with  fuzzy  sets,  called rough-fuzzy  computing,  as  a stronger  paradigm for uncertainty  handling, is  explained. Different applications  of  rough granules,  significance  of f-granulation  and certain emerging issues in  their performance are stated.  Generalized rough sets  using the concept of  fuzziness in granules as  well as in sets    are    defined   both    for    equivalence   and    tolerance relations.  Different tasks such  as case  generation, class-dependent rough-fuzzy granulation for classification, rough-fuzzy clustering and
defining entropy and various ambiguity measures for image analysis are then   addressed   in  this   regard,   explaining   the  nature   and characteristics of granules used therein. While the method of case generation with variable reduced dimension is useful  for mining  data sets  with  large dimension  and size,  class dependent granulation coupled with neighborhood rough sets for feature selection is  efficient in modeling  overlapping classes. Significance of a  new measure, called ''dispersion''  of classification performance, which  focuses  on confused  classes  for  higher  level analysis,  is explained  in this  regard. Superiority  of rough-fuzzy  clustering is illustrated for determining  bio-bases (c-medoids) in encoding protein sequence  for analysis.   Image  ambiguity measures,  which take  into account  both  the  fuzziness  in  boundary  regions,  and  the  rough
resemblance among  nearby gray levels  and nearby pixels,  are defined for various image analysis  tasks. Merits of incorporating the concept of rough granules in gray level in addition to fuzziness for computing entropy are  extensively demonstrated for  image segmentation problem, as an example. The talk concludes with stating  the future directions of research and challenges, and the relevance to natural computing.</Abstract>
</Event></TableEvents>
